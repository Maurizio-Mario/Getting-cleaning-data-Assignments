head(iris2)
fileUrlXML <- "view-source:http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens"
doc <- xmlTreeParse(fileUrlXML, useInternalNodes = TRUE)
library(XML)
fileUrlXML <- "view-source:http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens"
doc <- xmlTreeParse(fileUrlXML, useInternalNodes = TRUE)
fileUrlXML <- "http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens"
doc <- xmlTreeParse(fileUrlXML, useInternalNodes = TRUE)
download.file("view-source:http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens")
doc <- xmlTreeParse(fileUrlXML, useInternalNodes = TRUE)
doc <- xmlTreeParse(fileUrlXML, useInternal = TRUE)
help(package = "XLM")
history()
rm(list=ls())
help.start()
q()
help.start()
help(mean)
args(mean)
args(mean)
example(mean)
help.search(mean)
help.search("mean")
help.search("electoral")
help(read.xmls)
help(read.xlms)
help(read.xlsx)
help.search("read.xlsx")
??read.xlsx
help(package = "xlsx")
vignette()
vignette("xlsx")
RSiteSearch("crosstab")
q()
install.packages(data.table)
install.packages("data.table")
library(data.table)
help(packages = "data.table")
library(data.table)
help(package = data.table)
help("data.frame")
help(package = data.table)
help("data.frame")
DF = data.frame(x = rnorm(9), y = rep(c("a", "b", "c"), each = 3), z = rnorm(9))
df
DF
DT = data.table(x = rnorm(9, y = rep(c("a", "b", "c"), each = 3), z = rnorm(9))
DT = data.table(x = rnorm(9), y = rep(c("a", "b", "c"), each = 3), z = rnorm(9))
search()
DT = data.table(x = rnorm(9), y = rep(c("a", "b", "c"), each = 3), z = rnorm(9))
DT
head(DT, 3)
tables()
DT[2,]
DT[c(2, 3)]
DT[,c(2, 3)]
{
x = 1
y = 2
}
k = {print(10); 5}
print(k)
help(package = data.table)
help(package = data.table)
help(package = data.table)
DT[, list(mean(x), sum(z))]
DT[table(y)]
DT[, table(y)]
DT[, table(x)]
DT[, table(y)]
DT[, w =: z^2]
DT[, w := z^2]
DT
DT2 <- DT
DT[, y := 2]
DT
DT[, y := 2]
suppressWarnings(DT[, y := 2])
DT
head[DT, n = 3]
head(DT, n = 3)
head(DT2, n = 3)
set.seed(123)
DT <- data.table(x = sample(letters[↨1:3], 1E5, TRUE)
DT <- data.table(x = sample(letters[↨1:3], 1E5, TRUE))
DT <- data.table(x = sample(letters[1:3], 1E5, TRUE))
DT
DT[, .N, by = x]
DT1 <- data.table(x = c("a", "a", "b" "dt1"), y = 1 : 4)
DT2 <- data.table(x = c("a", "b" "dt2"), z = 5 : 7)
DT2 <- data.table(x = c("a", "b", "dt2"), z = 5 : 7)
DT2 <- data.table(x = c("a", "b", "dt2"), z = 5 : 7)
DT1 <- data.table(x = c("a", "a", "b", "dt1"), y = 1 : 4)
DT1, DT2
DT1
DT2
setkey(DT1, x), setkey(DT2, x)
DT1; DT2
setkey(DT1, x); setkey(DT2, x)
merge(DT1, DT2)
2 + 4 : 2
DT
2+4
4/2
2+4/2
(2+4)/2
pow2 <- function(x) x^2
pow2(4)
pow_fun <- function(x) {
pow <- function(y) {
x^y
}
pow
}
pow_fun(2)
pow_fun(2)
pow_fun <- function(x) {
pow <- function(2) {
x^2
}
pow
}
pow_fun <- function(x) {
pow <- function(y) {
x^y
}
pow
}
str(pow_fun)
square(3)
square <- pow_fun(2)
square(3)
square(3)
pow_fun <- function(x) {
pow <- function(y) {
y^x
}
pow
}
square <- pow_fun(2)
square(3)
cube <- pow_fun(3)
pow_fun(4)
incr_fun <- function(x) {
incremental <- function(y) {
y + x
}
incremental
}
add2 <- incr_fun(2)
add2(10)
add2(1:10)
add2(0:10)
add4 <- incr_fun(4)
add4(0:10)
?apply
example(apply)
exemple(apply)
example(apply)
example(mean)
example(apply)
apply(matrix(rep(1, 16), nrow = 4, ncol = 4), add2)
apply(matrix(rep(1, 16), nrow = 4, ncol = 4), fun = add2)
apply(matrix(1:16), nrow = 4, ncol = 4), fun = add2)
apply(matrix(1:16, nrow = 4, ncol = 4), fun = add2)
lapply(matrix(1:16, nrow = 4, ncol = 4), fun = add2)
apply(matrix(1:16, nrow = 4, ncol = 4), fun = add2)
?matrix
matrix(1:16, 4, 4)
matrix(rep(1, 16), 4, 4)
apply(matrix(rep(1, 16), 4, 4), FUN = add2
apply(matrix(rep(1, 16), 4, 4), FUN = add2)
apply(matrix(rep(1, 16), 4, 4), FUN = mean())
apply(matrix(rep(1, 16), 4, 4), FUN = add2())
apply(matrix(rep(1, 16), 4, 4), FUN = add2(2))
apply(dt <- matrix(rep(1, 16), 4, 4), FUN = add2(dt))
apply(dt <- matrix(rep(1, 16), 4, 4), FUN = add2(2))
lapply(rep(1, 10), mean)
lapply(rep(1, 10), add2)
lapply(matrix(rep(1, 10)), add2)
lapply(matrix(rep(1, 10), 4, 4), add2)
lapply(matrix(rep(1, 16), 4, 4), add2)
sapply(matrix(rep(1, 16), 4, 4), add2)
matrix(rep(1, 16), 4, 4)
apply(matrix(rep(1, 16), 4, 4), add2)
lapply(matrix(rep(1, 16), 4, 4), add2)
sapply(matrix(rep(1, 16), 4, 4), add2)
6%%2
6%%3
?(%%)
??%
6%%1
6%%4
6%%5
60%%2
60%%4
60%%7
60%%8
60%%9
egcd <- function(x, y) {
if (y == 0) return(x)
else return(egcd(y, x %% y))
}
egcd(7, 6)
egcd(8, 6)
egcd(9, 6)
egcd(12, 6)
egcd(12, 6, 2)
rm(list = ls())
get wd
getwd()
setwd("C:\Users\MaurizioLocale\OneDrive\Data_Science\3 Getting and Cleaning Data\R programming")
setwd("C:OneDrive//Data_Science//3 Getting and Cleaning Data//R programming")
setwd("C://UsersMaurizioLocale//OneDrive//Data_Science//3 Getting and Cleaning Data//R programming")
setwd("C:/UsersMaurizioLocale/OneDrive/Data_Science/3 Getting and Cleaning Data/R programming")
setwd("C://UsersMaurizioLocale//OneDrive")
setwd("C://Users//MaurizioLocale//OneDrive")
setwd("C://Users//MaurizioLocale//OneDrive//Data_Science//3 Getting and Cleaning Data//R programming")
getwd()
arch()
library(XML)
Q3_url <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
Q3_url
Q3_data <- xmlTreeParse(Q3_url, useInternalNodes = TRUE)
Q3_data
root_nodes <- xmlRoot(Q3_data)
names(root_nodes)
root_nodes[[1]]
root_nodes[[1]][[2]]
Q3_url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
Q3_data <- xmlTreeParse(Q3_url, useInternalNodes = TRUE)
Q3_url <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
Q3_data <- xmlTreeParse(Q3_url, useInternalNodes = TRUE)
Q3_data
root_nodes <- xmlRoot(Q3_data)
names(root_nodes)
Q3_data <- xmlTreeParse(Q3_url, useInternal = TRUE)
root_nodes <- xmlRoot(Q3_data)
names(root_nodes)
root_nodes[[1]][[2]]
xmlName(root_nodes)
root_nodes[[1]][[2]]
root_nodes[[1]]
names(root_nodes)
root_nodes[[1]][[1]]
root_nodes[[1]][[2]]
root_nodes[[1]][[2]][["name"]]
root_nodes[[1]][[2]][["zipcode"]]
root_nodes[[length()]][[2]][["zipcode"]]
root_nodes[[length(Q3_data)]][[2]][["zipcode"]]
root_nodes[[length(Q3_data)]][[length(Q3_data)]][["zipcode"]]
subset(root_nodes[[length(Q3_data)]][[length(Q3_data)]][["zipcode" == 21224]])
1
root_nodes[[1]][[2]][["zipcode"]]
xmlSApply(root_nodes, xmlValue)
?xmlSApply
xmlSApply(root_nodes, root_nodes[[1]][[2]][["zipcode"]])
xmlSAppy(Q3_data), root_nodes[[1]][[2]][["zipcode"]])
xmlSAppy(Q3_data, root_nodes[[1]][[2]][["zipcode"]])
xmlSApply(Q3_data, root_nodes[[1]][[2]][["zipcode"]])
xmlSApply(root_nodes, root_nodes[[1]][[2]][["zipcode"]])
xmlSApply(root_nodes, subset(root_nodes[[1]][[2]][["zipcode"]]))
xmlSApply(root_nodes[[1]][[2]][["zipcode"]])
xmlSApply(root_nodes, [[1]][[2]][["zipcode"]])
xmlSApply(root_nodes, root_nodes[[1]][[2]][["zipcode"]])
xpathSApply(root_nodes, "//zipcode")
xpathSApply(root_nodes, "//zipcode", xmlValue)
xpathSApply(root_nodes, "//zipcode" == 24231, xmlValue)
xpathSApply(root_nodes, "//zipcode" == 24231, xmlValue)
xpathSApply(root_nodes, "//zipcode == 24231", xmlValue)
xpathSApply(root_nodes, "//zipcode", xmlValue)
zip_codes <- xpathSApply(root_nodes, "//zipcode", xmlValue)
zip_codes
sum(zip_codes == 21231)
source('C:/Users/MaurizioLocale/OneDrive/Data_Science/3 Getting and Cleaning Data/R programming/Quizz1_4.R', echo=TRUE)
Q3_url <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
Q3_url
Q3_data <- xmlTreeParse(Q3_url, useInternal = TRUE)
Q3_data
zip_codes <- xpathSApply(root_nodes, "//zipcode", xmlValue)
zip_codes
sum(zip_codes == 21231)
q()
rm(list = ls())
Q3_url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
help("download.file")
getwd()
Q3_data <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
Q3_data <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", "getdata%2Fdata%2Fss06pid.csv")
read.csv("getdata%2Fdata%2Fss06pid.csv")
Q3_down <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", "getdata%2Fdata%2Fss06pid.csv")
Q3_data <- read.csv("getdata%2Fdata%2Fss06pid.csv")
dim(Q3_data)
?fread
??fread
DT <- read.csv("getdata%2Fdata%2Fss06pid.csv")
rm(Q3_data)
library(data.table)
?fread
DT <- fread("getdata%2Fdata%2Fss06pid.csv")
DT
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
system.time()
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT$pwgtp15,by=DT$SEX))
Q3_down <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", "getdata%2Fdata%2Fss06pid.csv")
DT <- fread("getdata%2Fdata%2Fss06pid.csv")
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(replicate(10000(tapply(DT$pwgtp15,DT$SEX,mean)))
system.time(replicate(10000(tapply(DT$pwgtp15,DT$SEX,mean))))
system.time(replicate(10000, (tapply(DT$pwgtp15,DT$SEX,mean))))
system.time(replicate(1000, (tapply(DT$pwgtp15,DT$SEX,mean))))
system.time(replicate(1000, DT[,mean(pwgtp15),by=SEX]))
system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(replicate(1000, (tapply(DT$pwgtp15,DT$SEX,mean))))
system.time(replicate(1000, DT[,mean(pwgtp15),by=SEX]))
system.time(replicate(1000, sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(replicate(1000, mean(DT$pwgtp15,by=DT$SEX))
system.time(replicate(1000, (tapply(DT$pwgtp15,DT$SEX,mean))))
system.time(replicate(1000, DT[,mean(pwgtp15),by=SEX]))
system.time(replicate(1000, sapply(split(DT$pwgtp15,DT$SEX),mean)))
system.time(replicate(1000, mean(DT$pwgtp15,by=DT$SEX))
system.time(replicate(1000, mean(DT$pwgtp15,by=DT$SEX)))
mean(DT$pwgtp15,by=DT$SEX)
system.time(replicate(1000, mean(DT$pwgtp15,by=DT$SEX)))
system.time(replicate(1000, (tapply(DT$pwgtp15,DT$SEX,mean))))
system.time(replicate(1000, DT[,mean(pwgtp15),by=SEX]))
system.time(replicate(1000, sapply(split(DT$pwgtp15,DT$SEX),mean)))
system.time(replicate(1000, mean(DT$pwgtp15,by=DT$SEX)))
library(XML)
fileUrl <- "http://class.coursera.org/getdata-033/lecture"
dataXml <- xmlTreeParse(fileUrl, useInternalNodes = TRUE)
fileUrl <- "https://class.coursera.org/getdata-033/lecture"
dataXml <- xmlTreeParse(fileUrl, useInternalNodes = TRUE)
fileUrl <- "http://class.coursera.org/getdata-033/lecture"
dataXml <- xmlTreeParse(fileUrl, useInternalNodes = TRUE)
dataXml <- xmlTreeParse(fileUrl)
?xmlTreeParse
dataXml <- xmlTreeParse(fileUrl, useInternalNodes = TRUE,
isURL = TRUE)
fileUrl2 <- "http://hr.fbk.eu/en/jobs"
dataXml <- xmlTreeParse(fileUrl2, useInternalNodes = TRUE,
dataXml <- xmlTreeParse(fileUrl2, useInternalNodes = TRUE,isURL = TRUE)
dataXml <- xmlTreeParse(fileUrl2, useInternalNodes = TRUE,isURL = TRUE)
dataXml <- xmlTreeParse(fileUrl2, useInternalNodes = TRUE)
fileUrl2 <- "https://hr.fbk.eu/en/jobs"
dataXml <- xmlTreeParse(fileUrl2, useInternalNodes = TRUE)
fileUrl2 <- "http://hr.fbk.eu/en/jobs"
dataXml <- xmlTreeParse(fileUrl2, useInternalNodes = TRUE)
dataXml <- xmlTreeParse(fileUrl2, useInternal = TRUE)
rm(list = ls())
search("Rtools)
search("Rtools")
search(Rtools)
search()
install.packages("RTools")
install.packages('RMySQL',type='source')
library(RMySQL)
ucscDb <- dbConnect(MySQL(), user="genome",
host = "genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(ucscDb, "show database"); dbDisconnect(ucscDb);
result <- dbGetQuery(ucscDb, "show databases;"); dbDisconnect(ucscDb);
result
head(result)
allTables <- dbListTables(hg19)
hg19 <- dbConnect(MySQL(), user = "genome", db = "gh19",
host = "genome-mysql.cse.ucsc.edu")
hg19 <- dbConnect(MySQL(), user = "genome", db = "hg19",
host = "genome-mysql.cse.ucsc.edu")
allTables <- dbListTables(hg19)
length(allTables)
allTables[1:5]
dbListFields(hg19, "affyU133Plus2")
dbGetQuery(hg19, "select count(*) from affyU133Plus2")
affyData z- dbReadTable(hg19, "affyU133Plus2")
affyData <- dbReadTable(hg19, "affyU133Plus2")
head(affyData)
query <- dbSendQuery((hg19, "select * from affyU133Plus2 where
misMatches between 1 and 3"))
query <- dbSendQuery(hg19, "select * from affyU133Plus2 where
misMatches between 1 and 3")
affyMis <- fetch((query); quantile(affyMis$misMatches))
affyMis <- fetch(query); quantile(affyMis$misMatches)
affyMisSmall <- fetch(query, n = 10); dbClearResult(query);
dim(affyMis)
dim(affyMisSmall)
dbDisconnect(hg19)
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(rhdf5)
search()
library(rhdf5)
search()
install.packages("httr")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
rm(list = ls())
swirl()
read.csv("path2csv", stringsAsFactors = TRUE)
read.csv(path2csv, stringsAsFactors = TRUE)
read.csv(path2csv, stringsAsFactors = FALSE)
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
package_version("dplyr")
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch : country)
select(cran, country : r_arch)
cran
select(cran, -time)
-5:20
-5:-20
-(5:20)
select(-(x:size))
select-(x:size)
select(cran, -(x:size))
select(cran, (x:size))
select(cran, x:size)
select(cran)
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, country == "IN", r_version =< "3.0.2")
filter(cran, country == "IN", r_version <= "3.0.2")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500)
filter(cran, size > 100500, r_os == "linus-gnu")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na((c(3, 5, NA, 10)))
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(size : ip_id)
cran2 <- select(cran, size : ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, package, desc ip_id)
arrange(cran2, package, desc(r_version) ip_id)
arrange(cran2, package, desc(r_version), ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_gb = size_mb / 2^10)
mutate(cran3, size_gb = size_mb / 2^10)
mutate(cran3, size_gb = size_mb / 2^10)
mutate(cran3, size_gb)
mutate(cran3, size_mb)
size_mb
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
dir()
getwd()
setwd(".//R programming")
setwd("./R programming")
setwd("C:/Users/MaurizioLocale/OneDrive/Data_Science/3 Getting and Cleaning Data/R programming", setwd("./R programming")
setwd("C:/Users/MaurizioLocale/OneDrive/Data_Science/3 Getting and Cleaning Data/R programming"), setwd("./R programming")
setwd("C:/Users/MaurizioLocale/OneDrive/Data_Science/3 Getting and Cleaning Data/R programming"), setwd("../R programming")
setwd("C:/Users/MaurizioLocale/OneDrive/Data_Science/3 Getting and Cleaning Data/R programming"), setwd("C:/Users/MaurizioLocale/OneDrive/Data_Science/3 Getting and Cleaning Data/R programming")
setwd("C:/Users/MaurizioLocale/OneDrive/Data_Science/3 Getting and Cleaning Data/R programming"), setwd("C:/Users/MaurizioLocale/OneDrive/Data_Science/3 Getting and Cleaning Data/R programming")
setwd("C:/Users/MaurizioLocale/OneDrive/Data_Science/3 Getting and Cleaning Data/R programming")
getwd()
dir()
subject_train <- read.table(file = file.path("C:/Users/MaurizioLocale/OneDrive/Data_Science/3 Getting and Cleaning Data/Getting-cleaning-data-Assignments/UCI HAR Dataset/train", "subject_train.txt"), header = TRUE)
X_train <- read.table(file = file.path("C:/Users/MaurizioLocale/OneDrive/Data_Science/3 Getting and Cleaning Data/Getting-cleaning-data-Assignments/UCI HAR Dataset/train", "X_train.txt"), header = TRUE)
y_train <- read.table(file = file.path("C:/Users/MaurizioLocale/OneDrive/Data_Science/3 Getting and Cleaning Data/Getting-cleaning-data-Assignments/UCI HAR Dataset/train", "y_train.txt"), header = TRUE)
join_train_1 <- cbind(subject_train, y_train)
X_train <- read.table(file = file.path("C:/Users/MaurizioLocale/OneDrive/Data_Science/3 Getting and Cleaning Data/Getting-cleaning-data-Assignments/UCI HAR Dataset/train", "X_train.txt"), header = TRUE)
memory.limit()
rm(list = ls())
subject_train <- read.table(file = file.path("C:/Users/MaurizioLocale/OneDrive/Data_Science/3 Getting and Cleaning Data/Getting-cleaning-data-Assignments/UCI HAR Dataset/train", "subject_train.txt"), header = TRUE)
X_train <- read.table(file = file.path("C:/Users/MaurizioLocale/OneDrive/Data_Science/3 Getting and Cleaning Data/Getting-cleaning-data-Assignments/UCI HAR Dataset/train", "X_train.txt"), header = TRUE)
y_train <- read.table(file = file.path("C:/Users/MaurizioLocale/OneDrive/Data_Science/3 Getting and Cleaning Data/Getting-cleaning-data-Assignments/UCI HAR Dataset/train", "y_train.txt"), header = TRUE)
join_train_1 <- cbind(subject_train, y_train)
memory.limit()
memory.limit(size = 12058)
join_train_2 <- merge(join_train_1, X_train, all = TRUE)
dim(join_train_1)
dim(X_train)
join_train_2 <- cbind(join_train_1, X_train)
dim(join_train_2)
str(join_train_2)
head(join_train_2)
names(join_train_2)
exit()
q
q()
rm(list = ls())
install.packages("HTTR")
install.packages("httr")
library(httr)
